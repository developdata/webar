<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="initial-scale=1.0,user-scalable=no,maximum-scale=1,width=device-width">
    <title>My A-Frame Scene</title>
    <script src="https://aframe.io/releases/1.0.4/aframe.min.js"></script>
    <script src="https://unpkg.com/aframe-particle-system-component@1.0.x/dist/aframe-particle-system-component.min.js"></script> 
    <script src="https://rawgit.com/mayognaise/aframe-mouse-cursor-component/master/dist/aframe-mouse-cursor-component.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/donmccurdy/aframe-extras@v6.1.1/dist/aframe-extras.min.js"></script>

    <style>   
        #camera {
            opacity:1;
            position: fixed;
            background-size: 100% 100%;
            top: 0; left: 0; 
            min-width: 100%; min-height: 100%;
            width: auto; height: auto;
        }

    </style>
 

  </head>
  <body>
    //camera for the AR
    <video id="camera" autoplay playsinline></video>

    <div>Teachable Machine Image Model</div>
    <!-- <button type="button" onclick="init()">Start</button> -->
    <div id="webcam-container"></div>
    <div id="label-container"></div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>
    <script type="text/javascript">

        // the link to your model provided by Teachable Machine export panel
        const URL = "./model_ai/";

        let model;
        let webcam; 
        let labelContainer;
        let maxPredictions;
        init();

        // Load the image model and setup the webcam
        async function init() {
            const modelURL = URL + "model.json";
            const metadataURL = URL + "metadata.json";

            // load the model and metadata
            // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
            // or files from your local hard drive
            // Note: the pose library adds "tmImage" object to your window (window.tmImage)
            model = await tmImage.load(modelURL, metadataURL);
            maxPredictions = model.getTotalClasses();

            // Convenience function to setup a webcam
            const flip = true; // whether to flip the webcam
            webcam = new tmImage.Webcam(200, 200, flip); // width, height, flip
            await webcam.setup(); // request access to the webcam
            await webcam.play();
            window.requestAnimationFrame(loop);

            // append elements to the DOM
            document.getElementById("webcam-container").appendChild(webcam.canvas);
            labelContainer = document.getElementById("label-container");
            for (let i = 0; i < maxPredictions; i++) { // and class labels
                labelContainer.appendChild(document.createElement("div"));
            }
        }

        async function loop() {
            webcam.update(); // update the webcam frame
            await predict();
            window.requestAnimationFrame(loop);
        }

        // run the webcam image through the image model
        async function predict() {
            // predict can take in an image, video or canvas html element
            const prediction = await model.predict(webcam.canvas);
            for (let i = 0; i < maxPredictions; i++) {
                const classPrediction =
                    prediction[i].className + ": " + prediction[i].probability.toFixed(2);
                labelContainer.childNodes[i].innerHTML = classPrediction;
                console.log('class prediction: ' + classPrediction);
            }
        }    
    
    </script>

  <div id="ar-position">


    <a-scene vr-mode-ui="enabled: false" cursor="rayOrigin: mouse" raycaster="objects: #audio-button" >
    <!-- <a-scene vr-mode-ui="enabled: false"> -->

      <a-assets>
        <img id="playing" src="images/playing.png">
      </a-assets>
   
        <a-entity position="0 2.25 -15" particle-system="preset: rain; maxAge:5; color: #AAA; particleCount:2000;maxAge:2; texture: ./images/rain5.png; size: 2; "></a-entity>  

        
        <a-entity id="aframeCamera" camera look-controls mouse-cursor>

          <a-sphere position="0 0.8 -1.05" scale="0.02 0.009 0.02" material="color: blue; " ></a-sphere>
          
          <a-entity geometry="primitive: plane" position="0 0 -1" scale="50 50 1" material="color: grey; transparent: true; opacity: 0.4; metalness:0.3; " ></a-entity>


        </a-entity>

    </a-scene>
</div>
    <script>
    const video = document.getElementById('camera');
 
    var constraints = {
        audio: false,
        video: {
            facingMode: "environment",
        }
    };
      
    function cameraStart() {
        
        navigator.mediaDevices
            .getUserMedia(constraints)
            .then(function(stream) {
            video.srcObject = stream;
        })
        .catch(function(error) {
            console.error("Oops. Something is broken.", error);
        });
    }

        // Start the video stream when the window loads
    window.addEventListener("load", cameraStart, false);
 
</script>
  </body> 
</html>